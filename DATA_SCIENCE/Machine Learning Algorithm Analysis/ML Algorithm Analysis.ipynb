{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 51372,
     "status": "ok",
     "timestamp": 1576663433441,
     "user": {
      "displayName": "manasa pawar",
      "photoUrl": "",
      "userId": "07850461268939422328"
     },
     "user_tz": -660
    },
    "id": "DXBsIrx-XLAN",
    "outputId": "91aea465-bb5e-4ac8-89e3-482c9d7bddc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-8a8edb65-f97b-4e9a-96ca-7c3e5f65520c\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-8a8edb65-f97b-4e9a-96ca-7c3e5f65520c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data.csv to data.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEz0A26iXRkx"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import lasso_path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress = True, precision=3); #Options for NumPy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3163,
     "status": "error",
     "timestamp": 1576663458914,
     "user": {
      "displayName": "manasa pawar",
      "photoUrl": "",
      "userId": "07850461268939422328"
     },
     "user_tz": -660
    },
    "id": "YPz7u_VSXUY0",
    "outputId": "aa9e1e3e-1dea-4bd6-c786-cce780f62bfc"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e14f39f455cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Data.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Data.csv'"
     ]
    }
   ],
   "source": [
    "import io\n",
    "df3 = pd.read_csv(io.BytesIO(uploaded['Data.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ELuZyyzfXZr_"
   },
   "outputs": [],
   "source": [
    "df3.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjHnRH7TXdzK"
   },
   "outputs": [],
   "source": [
    "def dddraw(X_reduced,name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    # To getter a better understanding of interaction of the dimensions\n",
    "    # plot the first three PCA dimensions\n",
    "    fig = plt.figure(1, figsize=(8, 6))\n",
    "    ax = Axes3D(fig, elev=-150, azim=110)\n",
    "    ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=Y,cmap=plt.cm.Paired)\n",
    "    titel=\"First three directions of \"+name \n",
    "    ax.set_title(titel)\n",
    "    ax.set_xlabel(\"1st eigenvector\")\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.set_ylabel(\"2nd eigenvector\")\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.set_zlabel(\"3rd eigenvector\")\n",
    "    ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yi2cnWkGYADo"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import OrthogonalMatchingPursuit,RANSACRegressor,LogisticRegression,ElasticNetCV,HuberRegressor, Ridge, Lasso,LassoCV,Lars,BayesianRidge,SGDClassifier,LogisticRegressionCV,RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler,PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n",
    "\n",
    "    \n",
    "# import some data to play with\n",
    "X = df3\n",
    "Y=df3['RPDE']\n",
    "def rmsle(y_predicted, y_real):\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y_predicted)-np.log1p(y_real), 2)))\n",
    "def procenterror(y_predicted, y_real):\n",
    "     return np.round( np.mean(np.abs(y_predicted-y_real) )/ np.mean(y_real) *100 ,1)\n",
    "\n",
    "X = df3\n",
    "Y=np.round(df3['RPDE']*100) //preprocessing\n",
    "X=X.replace([np.inf, -np.inf], np.nan).fillna(value=0)\n",
    "#print(X) #nasty NaN\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "poly = PolynomialFeatures(2)\n",
    "X=poly.fit_transform(X)\n",
    "\n",
    "\n",
    "names = [\n",
    "         #'ElasticNet',\n",
    "         'SVC',\n",
    "         'kSVC',\n",
    "         'KNN',\n",
    "         'DecisionTree',\n",
    "         'RandomForestClassifier',\n",
    "         #'GridSearchCV',\n",
    "         'HuberRegressor',\n",
    "         'Ridge',\n",
    "         'Lasso',\n",
    "         'LassoCV',\n",
    "         'Lars',\n",
    "         #'BayesianRidge',\n",
    "         'SGDClassifier',\n",
    "         'RidgeClassifier',\n",
    "         'LogisticRegression',\n",
    "         'OrthogonalMatchingPursuit',\n",
    "         #'RANSACRegressor',\n",
    "         ]\n",
    "\n",
    "classifiers = [\n",
    "    #ElasticNetCV(cv=10, random_state=0),\n",
    "    SVC(),\n",
    "    SVC(kernel = 'rbf', random_state = 0),\n",
    "    KNeighborsClassifier(n_neighbors = 1),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators = 200),\n",
    "    #GridSearchCV(SVC(),param_grid, refit = True, verbose = 1),\n",
    "    HuberRegressor(fit_intercept=True, alpha=0.0, max_iter=100,epsilon=2.95),\n",
    "    Ridge(fit_intercept=True, alpha=0.0, random_state=0, normalize=True),\n",
    "    Lasso(alpha=0.05),\n",
    "    LassoCV(),\n",
    "    Lars(n_nonzero_coefs=10),\n",
    "    #BayesianRidge(),\n",
    "    SGDClassifier(),\n",
    "    RidgeClassifier(),\n",
    "    LogisticRegression(),\n",
    "    OrthogonalMatchingPursuit(),\n",
    "    #RANSACRegressor(),\n",
    "]\n",
    "correction= [0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "temp=zip(names,classifiers,correction)\n",
    "print(temp)\n",
    "\n",
    "for name, clf,correct in temp:\n",
    "    regr=clf.fit(X,Y)\n",
    "    #print( name,'% errors', abs(regr.predict(X)+correct-Y).sum()/(Y.sum())*100)\n",
    "    print(name,'%error',procenterror(regr.predict(X),Y),'rmsle',rmsle(regr.predict(X),Y))\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score, precision_score, recall_score\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(name,'Confusion Matrix')\n",
    "    print(confusion_matrix(Y, np.round(regr.predict(X) ) ) )\n",
    "    print('--'*40)\n",
    "\n",
    "    # Classification Report\n",
    "    print('Classification Report')\n",
    "    print(classification_report(Y,np.round( regr.predict(X) ) ))\n",
    "\n",
    "    # Accuracy\n",
    "    print('--'*40)\n",
    "    logreg_accuracy = round(accuracy_score(Y, np.round( regr.predict(X) ) ) * 100,2)\n",
    "    print('Accuracy', logreg_accuracy,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OnQoVJUNYA70"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNVpUTytYDPh"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA,SparsePCA,NMF, LatentDirichletAllocation,FactorAnalysis\n",
    "from sklearn.random_projection import GaussianRandomProjection,SparseRandomProjection\n",
    "from sklearn.cluster import KMeans,Birch\n",
    "import statsmodels.formula.api as sm\n",
    "from scipy import linalg\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler,PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rmsle(y_predicted, y_real):\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y_predicted)-np.log1p(y_real), 2)))\n",
    "def procenterror(y_predicted, y_real):\n",
    "     return ( np.mean(np.abs(y_predicted-y_real) )/ np.mean(y_real) *100 ).round()\n",
    "\n",
    "n_col=3\n",
    "X = df3\n",
    "Y=df3['RPDE']\n",
    "def rmsle(y_predicted, y_real):\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y_predicted)-np.log1p(y_real), 2)))\n",
    "def procenterror(y_predicted, y_real):\n",
    "     return np.round( np.mean(np.abs(y_predicted-y_real) )/ np.mean(y_real) *100 ,1)\n",
    "\n",
    "names = [\n",
    "         'PCA',\n",
    "         'FastICA',\n",
    "         'Gauss',\n",
    "         'KMeans',\n",
    "          #'SparsePCA',\n",
    "         'SparseRP',\n",
    "         'Birch',\n",
    "         #'NMF',    \n",
    "         #'LatentDietrich',    \n",
    "        ]\n",
    "\n",
    "classifiers = [\n",
    "    PCA(n_components=n_col),\n",
    "    FastICA(n_components=n_col),\n",
    "    GaussianRandomProjection(n_components=3),\n",
    "    KMeans(n_clusters=3),\n",
    "  \n",
    "    SparseRandomProjection(n_components=n_col, dense_output=True),\n",
    "    Birch(branching_factor=10, n_clusters=2,threshold=0.5),\n",
    "     \n",
    "  \n",
    "    ]\n",
    "correction= [1,1,0,0,0,0]\n",
    "\n",
    "temp=zip(names,classifiers,correction)\n",
    "print(temp)\n",
    "\n",
    "for name, clf,correct in temp:\n",
    "    Xr=clf.fit_transform(X,Y)\n",
    "    dddraw(Xr,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-X7-XyYYNdE"
   },
   "source": [
    "Analyzing Variables to Find the Dependent Variable\n",
    "\n",
    "As it can be seen, the table doesn't tell you what the dependent variable of this data set is. So we must discover it. To do so, we find the correlation matrix and see which column has the highest average correlation constant. This is obviously for demonstration purposes and it cannot be used as a way of determining a \"dependent variable\". #\n",
    "\n",
    "Qualitative Look at Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UwXYtsTZYXih"
   },
   "outputs": [],
   "source": [
    "corrMat = df3[::].corr(); \n",
    "sns.heatmap(corrMat, vmax=0.8, square = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bjuj3YWWYeEV"
   },
   "source": [
    "Quantitative Look at Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwmfaWf4YfOY"
   },
   "outputs": [],
   "source": [
    "print(corrMat);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgNVTnPqYk-t"
   },
   "source": [
    "After some simple calculations, one can see that Jitter(Percent) seems to generally have the highest percent of correlation with all of the other variables. Thus, let us use that as the dependent variable and the rest as the independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eC9F_HjHYp05"
   },
   "outputs": [],
   "source": [
    "X = df3.values[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]] # First 19 columns of data\n",
    "y = df3.values[:, 19]; # Last col of data\n",
    "X = np.array(X); \n",
    "X = sm.add_constant(X); \n",
    "results = sm.OLS(endog=y, exog = X).fit(); \n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePkVc-pcYz3c"
   },
   "source": [
    "As it can be, only some of the above variables are truly contributing to the regression. In particular, the following do not seem to contribute to the model as much as the other variables because they are less than 2 standard deviations from the mean: x1, x2, x6, x8, x11, x14 and x18. In other words, these variables are accepted by the null hypothesis. Thus, let us see how things change if we ignore these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1CRbgnOY01l"
   },
   "outputs": [],
   "source": [
    "X = df3.values[:,[2,3,4,6,8,9,11,12,14,15,16,18]] # First 19 columns of data\n",
    "y = df3.values[:, 19]; # Last col of data\n",
    "X = np.array(X); \n",
    "X = sm.add_constant(X); \n",
    "results1 = sm.OLS(endog=y, exog = X).fit(); \n",
    "\n",
    "print(results1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tw33rVFkY4wV"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n\\nβ =\", results1.params) #new beta vector for linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0HhWrzsuY_uO"
   },
   "source": [
    "Some of the t-values have changed and the R-squared variable has decreased, but the new model seems to predict the Jitter percentage as well as the old model. Thus, ignoring those certain variables with the low t-scores did not do much damage.\n",
    "\n",
    "Let us See how Ridge Regression Works on this Data se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTKmgdKYZA7C"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = df3.values[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]] # First 19 columns of data\n",
    "y = df3.values[:, 19]; # Last col of data\n",
    "\n",
    "n_alphas = 200\n",
    "\n",
    "alphas = np.logspace(-10, -2, n_alphas)\n",
    "regr = linear_model.Ridge(fit_intercept = False)\n",
    "\n",
    "coefs = []; \n",
    "for a in alphas:\n",
    "    regr.set_params(alpha = a)\n",
    "    regr.fit(X,y)\n",
    "    coefs.append(regr.coef_)\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2DMOugBZIkV"
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "X = df3.values[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]] # First 19 columns of data\n",
    "y = df3.values[:, 19]; # Last col of data\n",
    "\n",
    "eps = 5e-20\n",
    "alphas_lasso, coefs_lasso, _ = lasso_path(X, y, eps, fit_intercept = False)\n",
    "\n",
    "plt.figure(1)\n",
    "ax = plt.gca()\n",
    "colors = cycle(['b', 'r', 'g', 'c', 'k']);\n",
    "neg_log_alphas_lasso = -np.log10(alphas_lasso)\n",
    "for coef_l, c in zip(coefs_lasso, colors):\n",
    "    l1 = plt.plot(neg_log_alphas_lasso, coef_l, c=c);\n",
    "   \n",
    "plt.xlabel('-Log(alpha)')\n",
    "plt.ylabel('coefficients')\n",
    "plt.title('Lasso Paths')\n",
    "plt.axis('tight')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#lassocoefs = []; \n",
    "#for a in alphas:\n",
    "#    regr.set_params(alpha = a)\n",
    "#    regr.fit(X,y)\n",
    "#    lassocoefs.append(regr.coef_)\n",
    "\n",
    "#plt.xlabel('-Log(alpha)');\n",
    "#plt.ylabel('coefficients');\n",
    "#plt.title('Lasso Paths');\n",
    "#plt.axis('tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2Y150wfZLsW"
   },
   "outputs": [],
   "source": [
    "print(\"Ridge   \", \"Lasso    \", \"OLS\")\n",
    "\n",
    "A  = [coefs[0], coefs_lasso.T[::-1][0], results.params[1:]]\n",
    "\n",
    "print(np.matrix(A).T)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
