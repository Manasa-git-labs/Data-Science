{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AUTOMATIC VALIDATION DL LAB.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"4Pn5Sbuqcsh0","colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1624897938095,"user_tz":-120,"elapsed":3095,"user":{"displayName":"manasa pawar","photoUrl":"","userId":"07850461268939422328"}},"outputId":"09af5bdc-921d-4211-97f5-7aeefd69a16d"},"source":["# MLP with automatic validation set\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import numpy\n","# fix random seed for reproducibility\n","numpy.random.seed(7)\n","# load pima indians dataset\n","dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n","# split into input (X) and output (Y) variables\n","X = dataset[:,0:8]\n","Y = dataset[:,8]\n","# create model\n","model = Sequential()\n","model.add(Dense(12, input_dim=8, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","# Compile model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","# Fit the model\n","model.fit(X, Y, validation_split=0.33, epochs=15, batch_size=10)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-172f342c9daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load pima indians dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pima-indians-diabetes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# split into input (X) and output (Y) variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    533\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: pima-indians-diabetes.csv not found."]}]},{"cell_type":"code","metadata":{"id":"9MnA_tktkpKs"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dIyzVtS1lV7c"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kidbuZlyj3FW","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1583224968815,"user_tz":-330,"elapsed":15158,"user":{"displayName":"manasa pawar","photoUrl":"","userId":"07850461268939422328"}},"outputId":"da16b962-057a-444d-8c2e-f36bf5f1d4f6"},"source":["# MLP with manual validation set\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.model_selection import train_test_split\n","import numpy\n","# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)\n","# load pima indians dataset\n","dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n","# split into input (X) and output (Y) variables\n","X = dataset[:,0:8]\n","Y = dataset[:,8]\n","# split into 67% for train and 33% for test\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n","# create model\n","model = Sequential()\n","model.add(Dense(12, input_dim=8, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","# Compile model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","# Fit the model\n","model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 514 samples, validate on 254 samples\n","Epoch 1/150\n","514/514 [==============================] - 0s 791us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 2/150\n","514/514 [==============================] - 0s 169us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 3/150\n","514/514 [==============================] - 0s 163us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 4/150\n","514/514 [==============================] - 0s 161us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 5/150\n","514/514 [==============================] - 0s 170us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 6/150\n","514/514 [==============================] - 0s 170us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 7/150\n","514/514 [==============================] - 0s 192us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 8/150\n","514/514 [==============================] - 0s 170us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 9/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 10/150\n","514/514 [==============================] - 0s 162us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 11/150\n","514/514 [==============================] - 0s 163us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 12/150\n","514/514 [==============================] - 0s 174us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 13/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 14/150\n","514/514 [==============================] - 0s 175us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 15/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 16/150\n","514/514 [==============================] - 0s 167us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 17/150\n","514/514 [==============================] - 0s 178us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 18/150\n","514/514 [==============================] - 0s 170us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 19/150\n","514/514 [==============================] - 0s 170us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 20/150\n","514/514 [==============================] - 0s 160us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 21/150\n","514/514 [==============================] - 0s 185us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 22/150\n","514/514 [==============================] - 0s 173us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 23/150\n","514/514 [==============================] - 0s 163us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 24/150\n","514/514 [==============================] - 0s 168us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 25/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 26/150\n","514/514 [==============================] - 0s 173us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 27/150\n","514/514 [==============================] - 0s 164us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 28/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 29/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 30/150\n","514/514 [==============================] - 0s 171us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 31/150\n","514/514 [==============================] - 0s 161us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 32/150\n","514/514 [==============================] - 0s 164us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 33/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 34/150\n","514/514 [==============================] - 0s 171us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 35/150\n","514/514 [==============================] - 0s 174us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 36/150\n","514/514 [==============================] - 0s 182us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 37/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 38/150\n","514/514 [==============================] - 0s 169us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 39/150\n","514/514 [==============================] - 0s 184us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 40/150\n","514/514 [==============================] - 0s 164us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 41/150\n","514/514 [==============================] - 0s 176us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 42/150\n","514/514 [==============================] - 0s 169us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 43/150\n","514/514 [==============================] - 0s 167us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 44/150\n","514/514 [==============================] - 0s 170us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 45/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 46/150\n","514/514 [==============================] - 0s 162us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 47/150\n","514/514 [==============================] - 0s 170us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 48/150\n","514/514 [==============================] - 0s 164us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 49/150\n","514/514 [==============================] - 0s 166us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 50/150\n","514/514 [==============================] - 0s 168us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 51/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 52/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 53/150\n","514/514 [==============================] - 0s 152us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 54/150\n","514/514 [==============================] - 0s 158us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 55/150\n","514/514 [==============================] - 0s 170us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 56/150\n","514/514 [==============================] - 0s 175us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 57/150\n","514/514 [==============================] - 0s 154us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 58/150\n","514/514 [==============================] - 0s 153us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 59/150\n","514/514 [==============================] - 0s 160us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 60/150\n","514/514 [==============================] - 0s 175us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 61/150\n","514/514 [==============================] - 0s 166us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 62/150\n","514/514 [==============================] - 0s 168us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 63/150\n","514/514 [==============================] - 0s 173us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 64/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 65/150\n","514/514 [==============================] - 0s 167us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 66/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 67/150\n","514/514 [==============================] - 0s 175us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 68/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 69/150\n","514/514 [==============================] - 0s 164us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 70/150\n","514/514 [==============================] - 0s 169us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 71/150\n","514/514 [==============================] - 0s 171us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 72/150\n","514/514 [==============================] - 0s 179us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 73/150\n","514/514 [==============================] - 0s 188us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 74/150\n","514/514 [==============================] - 0s 158us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 75/150\n","514/514 [==============================] - 0s 162us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 76/150\n","514/514 [==============================] - 0s 178us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 77/150\n","514/514 [==============================] - 0s 171us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 78/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 79/150\n","514/514 [==============================] - 0s 169us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 80/150\n","514/514 [==============================] - 0s 166us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 81/150\n","514/514 [==============================] - 0s 167us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 82/150\n","514/514 [==============================] - 0s 181us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 83/150\n","514/514 [==============================] - 0s 173us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 84/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 85/150\n","514/514 [==============================] - 0s 170us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 86/150\n","514/514 [==============================] - 0s 167us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 87/150\n","514/514 [==============================] - 0s 186us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 88/150\n","514/514 [==============================] - 0s 163us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 89/150\n","514/514 [==============================] - 0s 175us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 90/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 91/150\n","514/514 [==============================] - 0s 176us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 92/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 93/150\n","514/514 [==============================] - 0s 167us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 94/150\n","514/514 [==============================] - 0s 183us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 95/150\n","514/514 [==============================] - 0s 169us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 96/150\n","514/514 [==============================] - 0s 164us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 97/150\n","514/514 [==============================] - 0s 176us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 98/150\n","514/514 [==============================] - 0s 173us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 99/150\n","514/514 [==============================] - 0s 188us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 100/150\n","514/514 [==============================] - 0s 171us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 101/150\n","514/514 [==============================] - 0s 168us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 102/150\n","514/514 [==============================] - 0s 175us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 103/150\n","514/514 [==============================] - 0s 180us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 104/150\n","514/514 [==============================] - 0s 168us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 105/150\n","514/514 [==============================] - 0s 164us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 106/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 107/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 108/150\n","514/514 [==============================] - 0s 179us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 109/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 110/150\n","514/514 [==============================] - 0s 180us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 111/150\n","514/514 [==============================] - 0s 171us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 112/150\n","514/514 [==============================] - 0s 177us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 113/150\n","514/514 [==============================] - 0s 164us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 114/150\n","514/514 [==============================] - 0s 181us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 115/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 116/150\n","514/514 [==============================] - 0s 166us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 117/150\n","514/514 [==============================] - 0s 168us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 118/150\n","514/514 [==============================] - 0s 196us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 119/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 120/150\n","514/514 [==============================] - 0s 176us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 121/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 122/150\n","514/514 [==============================] - 0s 166us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 123/150\n","514/514 [==============================] - 0s 175us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 124/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 125/150\n","514/514 [==============================] - 0s 174us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 126/150\n","514/514 [==============================] - 0s 169us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 127/150\n","514/514 [==============================] - 0s 162us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 128/150\n","514/514 [==============================] - 0s 169us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 129/150\n","514/514 [==============================] - 0s 179us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 130/150\n","514/514 [==============================] - 0s 167us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 131/150\n","514/514 [==============================] - 0s 168us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 132/150\n","514/514 [==============================] - 0s 168us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 133/150\n","514/514 [==============================] - 0s 197us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 134/150\n","514/514 [==============================] - 0s 172us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 135/150\n","514/514 [==============================] - 0s 161us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 136/150\n","514/514 [==============================] - 0s 164us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 137/150\n","514/514 [==============================] - 0s 176us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 138/150\n","514/514 [==============================] - 0s 167us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 139/150\n","514/514 [==============================] - 0s 173us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 140/150\n","514/514 [==============================] - 0s 164us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 141/150\n","514/514 [==============================] - 0s 181us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 142/150\n","514/514 [==============================] - 0s 174us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 143/150\n","514/514 [==============================] - 0s 168us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 144/150\n","514/514 [==============================] - 0s 171us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 145/150\n","514/514 [==============================] - 0s 176us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 146/150\n","514/514 [==============================] - 0s 165us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 147/150\n","514/514 [==============================] - 0s 179us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 148/150\n","514/514 [==============================] - 0s 190us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 149/150\n","514/514 [==============================] - 0s 197us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n","Epoch 150/150\n","514/514 [==============================] - 0s 204us/step - loss: 5.5190 - acc: 0.6576 - val_loss: 5.8381 - val_acc: 0.6378\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fad22b37400>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"f9yqzB5BlX3k","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1583225486006,"user_tz":-330,"elapsed":129177,"user":{"displayName":"manasa pawar","photoUrl":"","userId":"07850461268939422328"}},"outputId":"4526d6df-7d82-4dc6-ef8f-8520b3f39d99"},"source":["# MLP for Pima Indians Dataset with 10-fold cross validation\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from sklearn.model_selection import StratifiedKFold\n","import numpy\n","# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)\n","# load pima indians dataset\n","dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n","# split into input (X) and output (Y) variables\n","X = dataset[:,0:8]\n","Y = dataset[:,8]\n","# define 10-fold cross validation test harness\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","cvscores = []\n","for train, test in kfold.split(X, Y):\n","  # create model\n","\tmodel = Sequential()\n","\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n","\tmodel.add(Dense(8, activation='relu'))\n","\tmodel.add(Dense(1, activation='sigmoid'))\n","\t# Compile model\n","\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\t# Fit the model\n","\tmodel.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n","\t# evaluate the model\n","\tscores = model.evaluate(X[test], Y[test], verbose=0)\n","\tprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","\tcvscores.append(scores[1] * 100)\n","print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["acc: 79.22%\n","acc: 79.22%\n","acc: 72.73%\n","acc: 66.23%\n","acc: 71.43%\n","acc: 64.94%\n","acc: 64.94%\n","acc: 72.73%\n","acc: 71.05%\n","acc: 77.63%\n","72.01% (+/- 5.21%)\n"],"name":"stdout"}]}]}